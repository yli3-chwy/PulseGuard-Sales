{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "import random\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.constant import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = get_absolute_path(\n",
    "    'one_week.csv',\n",
    "    'data',\n",
    "    PROJECT_BASE_DIR\n",
    ")\n",
    "\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PRICE_SNAPSHOT_DATE', 'CATEGORY_LEVEL1', 'CATEGORY_LEVEL2',\n",
       "       'CATEGORY_LEVEL3', 'MERCH_CLASSIFICATION1', 'MERCH_CLASSIFICATION2',\n",
       "       'MERCH_CLASSIFICATION3', 'LIST_PRICE', 'RATING_AVG', 'RATING_CNT',\n",
       "       'PRODUCT_PART_NUMBER', 'TOTAL_UNITS', 'TOTAL_CURRENT_ON_HAND',\n",
       "       'NUM_DISTINCT_UNIQUE_VISIT_ID', 'TOTAL_DISTINCT_CUSTOMER_IDS',\n",
       "       'TOTAL_HIT_NUMBER', 'RECORD_HIT_NUMBER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'PRODUCT_CATEGORY_LEVEL1' and 'PRODUCT_CATEGORY_LEVEL3' into a new column\n",
    "data['SEGMENT'] = data['CATEGORY_LEVEL1'] + ' - ' + data['MERCH_CLASSIFICATION3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120498"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120498 entries, 0 to 120497\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   PRICE_SNAPSHOT_DATE           120498 non-null  object \n",
      " 1   CATEGORY_LEVEL1               120498 non-null  object \n",
      " 2   CATEGORY_LEVEL2               120498 non-null  object \n",
      " 3   CATEGORY_LEVEL3               120498 non-null  object \n",
      " 4   MERCH_CLASSIFICATION1         120498 non-null  object \n",
      " 5   MERCH_CLASSIFICATION2         120498 non-null  object \n",
      " 6   MERCH_CLASSIFICATION3         120498 non-null  object \n",
      " 7   LIST_PRICE                    104171 non-null  float64\n",
      " 8   RATING_AVG                    120498 non-null  float64\n",
      " 9   RATING_CNT                    120498 non-null  int64  \n",
      " 10  PRODUCT_PART_NUMBER           120498 non-null  int64  \n",
      " 11  TOTAL_UNITS                   120498 non-null  float64\n",
      " 12  TOTAL_CURRENT_ON_HAND         120498 non-null  int64  \n",
      " 13  NUM_DISTINCT_UNIQUE_VISIT_ID  120498 non-null  int64  \n",
      " 14  TOTAL_DISTINCT_CUSTOMER_IDS   120498 non-null  int64  \n",
      " 15  TOTAL_HIT_NUMBER              120498 non-null  int64  \n",
      " 16  RECORD_HIT_NUMBER             120498 non-null  int64  \n",
      " 17  SEGMENT                       120498 non-null  object \n",
      "dtypes: float64(3), int64(7), object(8)\n",
      "memory usage: 16.5+ MB\n",
      "None\n",
      "          LIST_PRICE     RATING_AVG     RATING_CNT  PRODUCT_PART_NUMBER  \\\n",
      "count  104171.000000  120498.000000  120498.000000         1.204980e+05   \n",
      "mean       44.868818       3.641640      80.626309         5.879398e+07   \n",
      "std        31.583818       1.440005     143.724219         2.346575e+08   \n",
      "min         1.490000       0.000000       0.000000         4.536700e+04   \n",
      "25%        23.880000       3.650000       6.000000         9.203800e+04   \n",
      "50%        37.990000       4.132600      29.000000         2.139340e+05   \n",
      "75%        55.990000       4.450000      88.000000         5.725900e+05   \n",
      "max       342.930000       5.000000    1674.000000         1.000059e+09   \n",
      "\n",
      "         TOTAL_UNITS  TOTAL_CURRENT_ON_HAND  NUM_DISTINCT_UNIQUE_VISIT_ID  \\\n",
      "count  120498.000000          120498.000000                 120498.000000   \n",
      "mean       10.123338             408.575819                    204.621653   \n",
      "std        25.274319            1001.917952                    525.183980   \n",
      "min         0.000000               0.000000                      0.000000   \n",
      "25%         0.000000               0.000000                     16.000000   \n",
      "50%         2.000000              73.000000                     77.000000   \n",
      "75%         9.000000             382.000000                    212.000000   \n",
      "max       656.000000           25064.000000                  71571.000000   \n",
      "\n",
      "       TOTAL_DISTINCT_CUSTOMER_IDS  TOTAL_HIT_NUMBER  RECORD_HIT_NUMBER  \n",
      "count                120498.000000      1.204980e+05      120498.000000  \n",
      "mean                    136.764809      1.476735e+05         399.754900  \n",
      "std                     369.454998      3.036628e+05         910.511615  \n",
      "min                       0.000000      0.000000e+00           0.000000  \n",
      "25%                      10.000000      1.000525e+04          32.000000  \n",
      "50%                      51.000000      5.851700e+04         153.000000  \n",
      "75%                     142.000000      1.580220e+05         409.000000  \n",
      "max                   47494.000000      1.453796e+07       87220.000000  \n",
      "PRICE_SNAPSHOT_DATE                 0\n",
      "CATEGORY_LEVEL1                     0\n",
      "CATEGORY_LEVEL2                     0\n",
      "CATEGORY_LEVEL3                     0\n",
      "MERCH_CLASSIFICATION1               0\n",
      "MERCH_CLASSIFICATION2               0\n",
      "MERCH_CLASSIFICATION3               0\n",
      "LIST_PRICE                      16327\n",
      "RATING_AVG                          0\n",
      "RATING_CNT                          0\n",
      "PRODUCT_PART_NUMBER                 0\n",
      "TOTAL_UNITS                         0\n",
      "TOTAL_CURRENT_ON_HAND               0\n",
      "NUM_DISTINCT_UNIQUE_VISIT_ID        0\n",
      "TOTAL_DISTINCT_CUSTOMER_IDS         0\n",
      "TOTAL_HIT_NUMBER                    0\n",
      "RECORD_HIT_NUMBER                   0\n",
      "SEGMENT                             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Basic Information about the Datasets\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Dog - Wet Food Toppings', 'Dog - Freeze-Dried Food',\n",
       "       'Cat - Wet Food Toppings',\n",
       "       'Cat - Freeze-Dried & Dehydrated Food Toppings',\n",
       "       'Cat - Freeze-Dried Food', 'Dog - Dry Food', 'Cat - Dry Food',\n",
       "       'Cat - Wet Food', 'Dog - Wet Food', 'Dog - Dehydrated Food',\n",
       "       'Dog - Freeze-Dried & Dehydrated Food Toppings',\n",
       "       'Cat - Dehydrated Food', 'Dog - Dry Food Toppings',\n",
       "       'Dog - Frozen Food', 'Cat - Frozen Food',\n",
       "       'Cat - Dry Food Toppings'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.SEGMENT.unique()))\n",
    "data.SEGMENT.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Algorithm / Gaussian Mixture Model for Anomaly Detection\n",
    "\n",
    "3 Major Things to Pay Attention to:\n",
    "\n",
    "1. Our data contains missing values (NaN), and the GaussianMixture algorithm does not handle missing values natively. To address this issue, we need to handle missing values (I just dropped the `NET_SALES` or `UNITS` records that contains missing values) in our data before fitting the model. \n",
    "2. Need to tune hyperparameter `n_components`.\n",
    "3. Need to decide the `threshold`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM Anomaly Detection Optimization\n",
    "\n",
    "- Hyperparameter Tuning\n",
    "- Optimize the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning `n_components`\n",
    "\n",
    "\n",
    "Tuning the n_components parameter in Gaussian Mixture Models (GMMs) involves finding the optimal number of components (clusters) that best captures the underlying structure of your data. Here are a few methods you can use to determine the appropriate number of components:\n",
    "\n",
    "1. Elbow Method:\n",
    "    Fit GMMs with different values of n_components and plot the log-likelihood or another relevant metric against the number of components.\n",
    "    Look for an \"elbow\" point where adding more components doesn't significantly improve the fit. This point is often considered a good choice for the number of clusters.\n",
    "\n",
    "2. Silhouette Score:\n",
    "    Calculate the silhouette score for different values of n_components. The silhouette score measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation). Higher silhouette scores indicate better-defined clusters.\n",
    "\n",
    "3. AIC and BIC:\n",
    "    Use the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to evaluate different model fits. Lower values indicate better models.\n",
    "\n",
    "4. Cross-Validation:\n",
    "    Perform cross-validation with different values of n_components to assess the model's performance on unseen data.\n",
    "\n",
    "Choose the number of components that maximizes the silhouette score, minimizes the AIC or BIC, or shows a prominent elbow point in the plots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104171\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "metric_cols = [\n",
    "    'LIST_PRICE', 'RATING_AVG', 'RATING_CNT'\n",
    "    , 'TOTAL_UNITS', 'TOTAL_CURRENT_ON_HAND'\n",
    "    # , 'NUM_DISTINCT_UNIQUE_VISIT_ID', \n",
    "    , 'TOTAL_DISTINCT_CUSTOMER_IDS'\n",
    "    , 'RECORD_HIT_NUMBER'\n",
    "]\n",
    "metrics_data = data[metric_cols].dropna()\n",
    "print(len(metrics_data))\n",
    "print(len(data)-len(metrics_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "metrics_scaled = scaler.fit_transform(metrics_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the Gaussian Mixture Model\n",
    "# gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=0)\n",
    "# gmm.fit(metrics_scaled)\n",
    "\n",
    "# # Predict the probability of each data point belonging to each component\n",
    "# probs = gmm.predict_proba(metrics_scaled)\n",
    "\n",
    "# # Find the component with the smallest weight\n",
    "# smallest_component = np.argmin(gmm.weights_)\n",
    "\n",
    "# # Classify as an anomaly if the data point's highest probability is for the smallest component\n",
    "# is_anomaly = probs[:, smallest_component] > 0.5\n",
    "\n",
    "# # Extract the anomalies\n",
    "# anomalies = metrics_data[is_anomaly]\n",
    "\n",
    "# # Output the anomalies and their count\n",
    "# print(anomalies)\n",
    "# print('Number of anomalies detected:', len(anomalies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
